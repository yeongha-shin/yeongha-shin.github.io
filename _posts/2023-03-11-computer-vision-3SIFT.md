---
layout: post
title: ComputerVision // blob detection, SIFT
subtitle: blob detection & SIFT
gh-repo: yeongha-shin
gh-badge: [star, fork, follow]
tags: [ComputerVision]
comments: true
author: Yeongha Shin
---

# A. 오늘 이것만은 알고가자
1. blob detection을 하는 원리 (어떻게 같은 덩어리인지 알아내는지)
2. SIFT 의 원리 (어떻게 feature를 선정하고, 같은 feature인지를 확인할 수 있는지)

즉, 이미지를 어떻게 표현하는지에 대해서 배워보자는 것이다 !

# B. 지난 시간 복습
- *컨볼류션* : 이전에는 컨볼류션에 대해서 배웠다 : 특정 필터에 대한 연산을 수행해서, 이미지에 처리를 할 수 있다
- *특별한 필터* :그 중에서도 가우시안 필터를 수행해서, 파라미터의 사이즈를 입력하고, 노이즈 처리 같은 것을 수행할 수 있따
- 이미지 그래디언트를 구해서 이미지의 음영의 이동방향에 대해서 구할 수 있었다
- *엣지 검출* : derivative of gausssian을 통해서 이동 방향에 대해서 알아내고, 엣지 디텍팅을 할 수 있었다. 엣지 디텍션에 대해서는 헤리스 코너 검출기를 통해서 계산하고, 고유값 분해를 통해서 이미지의 방향성을 계산해낼 수 있었따
- *코너 검출* : 고유값 분해를 통해서 엣지인지, 코너인지 알아낼 수 있다 ! 

# C. Blob Detection의 원리
### 1. Blob Detection이란 무엇인가?
- 코너 디텍션이랑 비슷하다고 한다
- 하나의 덩어리를 이루는 것들을 말한다 (맨날 사용하는 말인데 정확하게 몰랐다) 즉 주변과 구별되는 덩어리를 말한다
- 이를 위해서는 필터를 개발해야 한다고 한다 !
  - > 가우시안 미분 필터를 통해서 엣지를 검출할 수 있듯이 말이다 : 이 필터를 수행하면 변경점을 찾아낼 수 있다 
- 이렇게 변경점을 찾아내려면 어떤 필터를 알아내야 하는 것일까? 

### 2. 한개의 Blob이라고 판단하는 방법은?
### 1) filter 만들기
- 이런 필터를 만들기 위해서 2차 미분을 한 필터를 사용하고, x방향과 y방향에 대해서 수행하는 값을 합쳐서 사용해야 한다
- 그래서 사용하는 것이 *가우시안 라플라시안*이다 !
- 문제점 ) 블롭의 사이즈와, 필터의 사이즈가 맞지 않으면, 노이즈가 생길 수 있다고 한다
- 그렇다면 어떻게 적절한 사이즈를 찾아낼 수 있는 것일까?
- 시그마 파라미터를 키우면 되는 것인데, 블롭의 반지름 크기에 기반해서 필터의 스케일을 조절하면 되는 것이다
- 문제점 ) 필터의 사이즈를 키우게 되면, 결과에 대한 시그널이 진폭이 크게 나타나지 않는다. 따라서 정규화를 수행하는 단계를 해야 정확한 결과를 얻을 수 있다고 한다

### 2) 필터를 거친 이후, 스케일링 진행하기
- 필터의 크기, 즉 시그마의 제곱에 크기에 비례하게 스케일을 수행하는 과정을 거친다
- 근데 그 그 스케일의 크기를 어떻게 알아내냐 말이다 !
- 그래서 나온것이 여러개의 스케일을 가지는 필터를 다 수행하는 것이다 

### 3) 위치를 알아내는 방법
- 가장 픽셀값이 높은 곳이 있고, 증가 감소하는 방향이 있다는 것을 알아내서 한개의 블롭이 있다는 것을 알아낼 수 있다
- 이웃하는 픽셀값을 알아내고, 가장 높은 픽셀값을 가지는 지점이라는 것을 알아내는 것이다

# D. 어떻게 패턴을 설명할 것인가?
- 이제 우리는 블롭이 어딨는지 알아내었다!
- 그 이후에 블롭 근처에 있는 이웃 픽셀에 대해서 계산해 보는 것이다
- 문제 정의 ) 사진의 특정 지점이 전체 이미지에서 어느 부분에 있는지 어떻게 알아낼 수 있는가?
- 해결법 ) 그것을 위해서 descripter를 정의하고, Matching을 수행하면 된다
- 이를 위해서 나온것이 SIFT이다 !

# E. SIFT의 원리
### 1. SIFT란 무엇인가?
- 스케일이 바뀌는 특징 추출을 위한 방법이다
- 왜 이렇게 설명하냐면, 조명의 변화에 대해서 강건한 방법을 사용하기 위해서 이다 !

*계산 순서* 
1) 블롭 디텍션을 수행한다
2) keypoint filtering
3) 방향을 할당함
4) descripter를 계산함
  
### 2. feature를 추출하는 방법은? 매칭하는 방법은? 
- 이미지를 2x2 또는 4x4로 자른다
- 이것에 대해서 이미지 그래디언트를 계산한다
- 그 이후에 나눈 구역에 대해서 이미지 그래디언트를 종합한다. 이렇게 히스토그램을 만들어낸다

### 1) 스케일 공간을 계산한다
- i) 라플라시안 가우시간을 사용하기에는 계산이 오래 걸려서 Difference of Gaussian을 유사하게 계산한다
- ii) 그 이후에 여러개의 이미지 스케일에 대해서 feature를 찾아낸다

### 2) keypoint filtering
- 낮은 값을 가지는 점들을 걸러낸다

### 3) orientation assignment
- 이미지의 방향을 계산해 낸다
- 원래는 편미분을 수행해야 하는데, 이를 근사화 하기 위해서 이미지간의 픽셀 차이를 계산해 낸다 (소버 필터를 사용해서 말이다)
- 방향 히스토그램을 만들기 전에, 가장 방향성이 뚜렷한 방향을 찾고, 그 다음에 그것을 0점으로 만든 다음에 히스토그램을 만든다면, 이미지 변화량에 대해서도 강건한 결과를 얻어낼 수 있다고 한다 !

### 4) descriptor를 계산한다
- 16방향 또는 8방향의 히스토그램을 만들어낸다
- 이 전체를 유닛 길이로 정규화를 진행한다
- 선택적으로, PCA를 수행할수도 있다

# 마무리 하며
이 외에도 SURF, ORB도 있다 



